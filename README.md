# Ninth: The Native Language of Neuro-Symbolic AI

![Version](https://img.shields.io/badge/version-v0.5.1-blue.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)
![Status](https://img.shields.io/badge/status-experimental-orange.svg)

**Ninth** is a minimal, Turing-complete, differentiable stack-based programming language designed for **Integrated Function Calling** within LLMs.

Unlike traditional tool use (JSON/Python), Ninth allows Large Language Models to "think" in code. It combines the simplicity of Forth with the power of PyTorch autograd.

> **"The model doesn't see the code execution, it only sees the result. It's like a Ghost in the Machine."**

---

## ðŸš€ Key Features

*   **Differentiable by Design**: Every operation supports Autograd. You can run `[BACKWARD]` through the entire execution stack.
*   **Tensor-First**: The only data type is `torch.Tensor`. Scalars, vectors, and matrices are first-class citizens.
*   **Token Efficient**: No boilerplate. `[MATMUL]` is 1 token. Loop logic is minimal. Ideal for limited context windows.
*   **Turing Complete**: Supports Functions (`[DEF]`), Loops (`[REPEAT]`), and Branching (`[IF]`).
*   **Smart Shapes (v0.5.1)**: Supports dynamic tensor creation like `[2 4] [RANDN]`.

---

## ðŸ“¦ Installation

Ninth is extremely lightweight. You only need `torch`.

```bash
pip install torch numpy matplotlib
```

Clone the repo and run the interpreter:

```bash
git clone https://github.com/your-username/ninth.git
cd ninth
python ninth.py
```

---

## âš¡ Quick Start

### 1. Basic Math
Ninth uses RPN (Reverse Polish Notation).
```forth
[PROGRAM_START]
3 4 [ADD]     // Stack: 7
5 [MUL]       // Stack: 35
[PRINT]
[PROGRAM_END]
```

### 2. Autograd & Optimization
Ninth can calculate gradients and update variables. Here is how to find $\sqrt{16}$ using gradient descent:

```forth
[PROGRAM_START]
// Init x = 1.0 with gradients
1.0 [VAR] "x" [STORE]

// Training Loop (50 steps)
50 [REPEAT]
  "x" [LOAD] [DUP] [MUL]  // x^2
  16.0 [SUB] [DUP] [MUL]  // Loss = (x^2 - 16)^2
  
  [BACKWARD]              // Compute Gradients
  
  // SGD Step: x = x - 0.01 * grad
  "x" [LOAD] "x" [GRAD] 0.01 [MUL] [SUB] 
  [VAR] "x" [STORE]       // Update x
[END]

"Result:" [PRINT]
"x" [LOAD] [PEEK]         // Should be close to 4.0
[PROGRAM_END]
```

---

## ðŸ§  LLM Integration (System Prompt)

To make your LLM (GPT-4, Llama-3, Claude) use Ninth, inject this into the system prompt:

```text
You have access to a differentiable stack machine called "Ninth". 
To perform calculations, simulate logic, or optimize parameters, output code in a block:
[PROGRAM_START] ... code ... [PROGRAM_END]

Syntax:
- RPN: "3 4 [ADD]" -> 7
- Tensors: "[2 4] [RANDN]" -> 2x4 Matrix
- Variables: "val [VAR] 'name' [STORE]" and "'name' [LOAD]"
- Logic: "[IF] ... [ELSE] ... [ENDIF]"
- Loops: "N [REPEAT] ... [END]"
- Autograd: "[BACKWARD]" to compute gradients.
```

---

## ðŸ“Š Neural Network Example

Ninth v0.5.1 is powerful enough to define and train a neural network from scratch in ~20 lines of code.

See `examples/classifier.9th` for a full binary classification example (Linear -> ReLU -> Linear -> Sigmoid) that solves the $x+y>0$ problem.

---

## ðŸ—º Roadmap

- [x] **v0.1**: Basic Stack & Math
- [x] **v0.3**: Loops & Control Flow
- [x] **v0.5**: Smart Shapes & Stability
- [ ] **v0.6**: File I/O & Tensor Reshape Support
- [ ] **v0.7**: Standard Library
- [ ] **v1.0**: End-to-End LLM Fine-tuning Integration

## ðŸ“„ License

MIT License. Free to use for research and revolution.
```

## README IS AI GENERATED BY GEMINI 3.0 PRO
